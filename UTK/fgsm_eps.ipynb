{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from preprocessor import _imread as imread\n",
    "from preprocessor import _imresize as imresize\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.losses import categorical_crossentropy\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'male', 1: 'female'},\n",
       " {'female': 1, 'male': 0},\n",
       " {0: 'white', 1: 'black', 2: 'asian', 3: 'indian', 4: 'others'},\n",
       " {'asian': 2, 'black': 1, 'indian': 3, 'others': 4, 'white': 0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"data/UTKFace\"\n",
    "TRAIN_TEST_SPLIT = 0.7\n",
    "IM_WIDTH = IM_HEIGHT = 198\n",
    "input_shape = (IM_WIDTH, IM_HEIGHT, 3)\n",
    "ID_GENDER_MAP = {0: 'male', 1: 'female'}\n",
    "GENDER_ID_MAP = dict((g, i) for i, g in ID_GENDER_MAP.items())\n",
    "ID_RACE_MAP = {0: 'white', 1: 'black', 2: 'asian', 3: 'indian', 4: 'others'}\n",
    "RACE_ID_MAP = dict((r, i) for i, r in ID_RACE_MAP.items())\n",
    "\n",
    "ID_GENDER_MAP, GENDER_ID_MAP, ID_RACE_MAP, RACE_ID_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filepath(filepath):\n",
    "    try:\n",
    "        path, filename = os.path.split(filepath)\n",
    "        filename, ext = os.path.splitext(filename)\n",
    "        age, gender, race, _ = filename.split(\"_\")\n",
    "        return int(age), ID_GENDER_MAP[int(gender)], ID_RACE_MAP[int(race)]\n",
    "    except Exception as e:\n",
    "        print(filepath)\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/UTKFace/61_1_20170109142408075.jpg.chip.jpg\n",
      "data/UTKFace/39_1_20170116174525125.jpg.chip.jpg\n",
      "data/UTKFace/61_1_20170109150557335.jpg.chip.jpg\n"
     ]
    }
   ],
   "source": [
    "# create a pandas data frame of images, age, gender and race\n",
    "files = glob.glob(os.path.join(DATA_DIR, \"*.jpg\"))\n",
    "attributes = list(map(parse_filepath, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>data/UTKFace/28_1_0_20170116164219746.jpg.chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>data/UTKFace/24_1_0_20170117150731090.jpg.chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "      <td>data/UTKFace/24_1_1_20170113003752421.jpg.chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>indian</td>\n",
       "      <td>data/UTKFace/26_1_3_20170104235148954.jpg.chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51.0</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>data/UTKFace/51_0_0_20170117190825002.jpg.chip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender    race                                               file\n",
       "0  28.0  female   white  data/UTKFace/28_1_0_20170116164219746.jpg.chip...\n",
       "1  24.0  female   white  data/UTKFace/24_1_0_20170117150731090.jpg.chip...\n",
       "3  24.0  female   black  data/UTKFace/24_1_1_20170113003752421.jpg.chip...\n",
       "4  26.0  female  indian  data/UTKFace/26_1_3_20170104235148954.jpg.chip...\n",
       "5  51.0    male   white  data/UTKFace/51_0_0_20170117190825002.jpg.chip..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(attributes)\n",
    "df['file'] = files\n",
    "df.columns = ['age', 'gender', 'race', 'file']\n",
    "df = df.dropna()\n",
    "df = df[(df['age'] > 10) & (df['age'] < 65)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, input_shape):\n",
    "    image = imresize(image, input_shape[:2])\n",
    "    image = image.astype('float32')\n",
    "    image = image/255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "def predict(model, image):\n",
    "    predictions = model.predict(image)\n",
    "    return predictions\n",
    "\n",
    "def FGSM(x, model, race_label, gender_label, alpha_1, alpha_2):\n",
    "    sess = K.get_session()\n",
    "    x_adv1 = x\n",
    "    x_adv2 = x\n",
    "    x_adv3 = x\n",
    "    x_adv4 = x\n",
    "    x_adv5 = x\n",
    "    #alpha_1 = 1.\n",
    "    #alpha_2 = -1.\n",
    "    #print(list(map(lambda x: x.name, model.layers)))\n",
    "    # dense7 -> layer before race output\n",
    "    # dense8 -> layer before gender output\n",
    "    # dense_7 = model.get_layer('dense_7').output\n",
    "    # dense_7_grads = K.gradients(dense_7, model.input)\n",
    "\n",
    "    # dense_8 = model.get_layer('dense_8').output\n",
    "    # dense_8_grads = K.gradients(dense_8, model.input)\n",
    "\n",
    "    # final_grads = tf.constant(alpha_1) * dense_7_grads + tf.constant(alpha_2) * dense_8_grads\n",
    "    # grads = K.gradients(final_grads, model.input)\n",
    "    \n",
    "    # delta = K.sign(final_grads[0])\n",
    "    \n",
    "    race_output = model.get_layer('race_output').output\n",
    "    print(\"race_output {}\".format(race_output))\n",
    "    gender_output = model.get_layer('gender_output').output\n",
    "    print(\"gender_output {}\".format(gender_output))\n",
    "\n",
    "    race_loss = K.sum(categorical_crossentropy(race_label, race_output))\n",
    "    gender_loss = K.sum(categorical_crossentropy(gender_label, gender_output))\n",
    "    \n",
    "    #race_loss_val, gender_loss_val = sess.run([race_loss, gender_loss], feed_dict={model.input: x})\n",
    "    #print(race_loss_val, gender_loss_val)\n",
    "\n",
    "    loss = alpha_1 * race_loss + alpha_2 * gender_loss\n",
    "    grads = K.gradients(loss, model.input)\n",
    "    delta = K.sign(grads[0])\n",
    "\n",
    "    x_adv1 = x_adv1 + 0.1 * delta\n",
    "    x_adv2 = x_adv2 + 0.2 * delta\n",
    "    x_adv3 = x_adv3 + 0.3 * delta\n",
    "    x_adv4 = x_adv4 + 0.4 * delta\n",
    "    x_adv5 = x_adv5 + 0.5 * delta\n",
    "\n",
    "    x_adv1 = K.clip(x_adv1, 0.0 ,1.0)\n",
    "    x_adv2 = K.clip(x_adv2, 0.0 ,1.0)\n",
    "    x_adv3 = K.clip(x_adv3, 0.0 ,1.0)\n",
    "    x_adv4 = K.clip(x_adv4, 0.0 ,1.0)\n",
    "    x_adv5 = K.clip(x_adv5, 0.0 ,1.0)\n",
    "\n",
    "    gradients, x_adv1_array, x_adv2_array, x_adv3_array, x_adv4_array, x_adv5_array = sess.run([grads,\n",
    "                                                                                                x_adv1,\n",
    "                                                                                                x_adv2,\n",
    "                                                                                                x_adv3,\n",
    "                                                                                                x_adv4,\n",
    "                                                                                                x_adv5],\n",
    "                                                                                                feed_dict={model.input:x})\n",
    "    #print('GRADIENT SUM:{}'.format(np.sum(gradients[0])))\n",
    "    return x_adv1_array, x_adv2_array, x_adv3_array, x_adv4_array, x_adv5_array\n",
    "\n",
    "def plot_adversarial(img_list):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    eps = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    for n, img in enumerate(img_list):\n",
    "        ax = plt.subplot(2,3,n+1)\n",
    "        ax.set_title('Epsilon: {}'.format(eps[n]))\n",
    "        plt.imshow(img[0])\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(x, race_label, gender_label, alpha_1, alpha_2, eps, steps):\n",
    "    sess = K.get_session()\n",
    "    for step in range(steps):\n",
    "        # predictions = predict(model, x)\n",
    "        # print(predictions)\n",
    "        # print(x.shape)\n",
    "        x_adv = x\n",
    "        race_output = model.get_layer('race_output').output\n",
    "        gender_output = model.get_layer('gender_output').output\n",
    "\n",
    "        race_loss = K.sum(categorical_crossentropy(race_label, race_output))\n",
    "        gender_loss = K.sum(categorical_crossentropy(gender_label, gender_output))\n",
    "\n",
    "        loss = alpha_1 * race_loss + alpha_2 * gender_loss\n",
    "        grads = K.gradients(loss, model.input)\n",
    "        delta = K.sign(grads[0])\n",
    "\n",
    "        x_adv = x_adv + eps * delta\n",
    "        x_adv = K.clip(x_adv, 0.0, 1.0)\n",
    "        x_adv_array = sess.run([x_adv], feed_dict={model.input: x})\n",
    "        # print(x_adv_array[0].shape)\n",
    "        x = x_adv_array[0]\n",
    "        #break\n",
    "    return x_adv_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_model_path = \"./models/VGG16_adv_model.h5\"\n",
    "clean_model_path = \"./models/weighted_forked_VGG_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv_samples(x, model):\n",
    "    adv_sample = FGSM(x, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_adv_samples(generator, eps):\n",
    "    folder = \"adv_generated_imgs_pgd\"\n",
    "    for data in generator:\n",
    "        samples, labels, filenames = data\n",
    "        race_one_hot, gender_one_hot = labels[1], labels[2]\n",
    "        # running loop over a batch\n",
    "        # prediction = predict(model, samples)\n",
    "\n",
    "        adv_samples = PGD(samples, race_label=race_one_hot, gender_label=gender_one_hot,\n",
    "                          alpha_1=1., alpha_2=-1., eps=eps, steps=20)\n",
    "        for index in range(len(adv_samples)):\n",
    "            filename = filenames[index]\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, eps, filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[index]*255))\n",
    "            img.save(final_name)\n",
    "            \n",
    "            \"\"\"final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"1\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[0][index]*255))\n",
    "            img.save(final_name)\n",
    "\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"2\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[1][index]*255))\n",
    "            img.save(final_name)\n",
    "\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"3\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[2][index]*255))\n",
    "            img.save(final_name)\n",
    "\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"4\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[3][index]*255))\n",
    "            img.save(final_name)\n",
    "\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"5\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[4][index]*255))\n",
    "            img.save(final_name)\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "def get_data_generator(df, indices, for_training, batch_size=16):\n",
    "    # filenames variable is not being passed right now for the evaluation but would be\n",
    "    # required if we want to generate the dataset of adversarial images\n",
    "    images, ages, races, genders, filenames = [], [], [], [], []\n",
    "    while True:\n",
    "        for i in indices:\n",
    "            r = df.iloc[i]\n",
    "            file, age, race, gender = r['file'], r['age'], r['race_id'], r['gender_id']\n",
    "            im = Image.open(file)\n",
    "            im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "            im = np.array(im) / 255.0\n",
    "            #filenames.append(file)\n",
    "            images.append(im)\n",
    "            ages.append(age / max_age)\n",
    "            races.append(to_categorical(race, len(RACE_ID_MAP)))\n",
    "            genders.append(to_categorical(gender, 2))\n",
    "            if len(images) >= batch_size:\n",
    "                yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]#, filenames\n",
    "                images, ages, races, genders, filenames = [], [], [], [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed is not common with model training on the other notebook\n",
    "# p = np.random.permutation(len(df))\n",
    "# train_up_to = int(len(df) * TRAIN_TEST_SPLIT)\n",
    "# test_idx = p[train_up_to:]\n",
    "\n",
    "df['gender_id'] = df['gender'].map(lambda gender: GENDER_ID_MAP[gender])\n",
    "df['race_id'] = df['race'].map(lambda race: RACE_ID_MAP[race])\n",
    "\n",
    "max_age = df['age'].max()\n",
    "\n",
    "# test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0926 22:48:56.747976 139627063801664 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0926 22:49:05.903436 139627063801664 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(clean_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image(sample_num=None):\n",
    "    if sample_num is None:\n",
    "        random_record = df.sample().iloc[0]\n",
    "    else:\n",
    "        random_record = df.iloc[sample_num]\n",
    "    \n",
    "    img_path = random_record['file']\n",
    "    image = imread(img_path)\n",
    "    image = preprocess_image(image, input_shape)\n",
    "\n",
    "    race_label = random_record['race_id']\n",
    "    gender_label = random_record['gender_id']\n",
    "\n",
    "    race_one_hot = np_utils.to_categorical(race_label, len(ID_RACE_MAP))\n",
    "    gender_one_hot = np_utils.to_categorical(gender_label, len(ID_GENDER_MAP))\n",
    "\n",
    "    return image, gender_one_hot, race_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gender_one_hot, race_one_hot = random_image(114)\n",
    "\n",
    "predictions = predict(model, image)\n",
    "\n",
    "images = FGSM(image, model, race_one_hot, gender_one_hot, alpha_1 = 1., alpha_2 = 0.)\n",
    "\n",
    "plot_adversarial(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gender_one_hot, race_one_hot = random_image(114)\n",
    "\n",
    "#predictions = predict(model, image)\n",
    "\n",
    "#images = FGSM(image, model, race_one_hot, gender_one_hot, alpha_1 = 10., alpha_2 = -10.)\n",
    "image = PGD(image, model, race_one_hot, gender_one_hot, alpha_1 = 1., alpha_2 = -1., eps=0.1, steps=20)\n",
    "\n",
    "#plot_adversarial(image)\n",
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_adv_samples(test_gen, eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate clean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv_data_generator(df, indices, eps, for_training=False, batch_size=128):\n",
    "    images, ages, races, genders = [], [], [], []\n",
    "    folder = \"data/adv_generated_imgs_pgd\"\n",
    "    while True:\n",
    "        for i in indices:\n",
    "            r = df.iloc[i]\n",
    "            file, age, race, gender = r['file'], r['age'], r['race_id'], r['gender_id']\n",
    "            filename = \"{}/{}/{}/{}\".format(file.split(\"/\")[0], folder, str(eps), file.split(\"/\")[-1])\n",
    "            #if os.path.exists(filename):\n",
    "            im = Image.open(filename)\n",
    "            im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "            im = np.array(im) / 255.0\n",
    "            images.append(im)\n",
    "            ages.append(age / max_age)\n",
    "            races.append(to_categorical(race, len(RACE_ID_MAP)))\n",
    "            genders.append(to_categorical(gender, 2))\n",
    "            if len(images) >= batch_size:\n",
    "                print(\"yielded\")\n",
    "                yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]\n",
    "                images, ages, races, genders = [], [], [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas data frame of images, age, gender and race\n",
    "ADV_DATA_DIR = \"./data/adv_generated_imgs_pgd/0.2/\"\n",
    "files = glob.glob(os.path.join(ADV_DATA_DIR, \"*.jpg\"))\n",
    "attributes = list(map(parse_filepath, files))\n",
    "\n",
    "df = pd.DataFrame(attributes)\n",
    "df['file'] = files\n",
    "df.columns = ['age', 'gender', 'race', 'file']\n",
    "df = df.dropna()\n",
    "df = df[(df['age'] > 10) & (df['age'] < 65)]\n",
    "#df.head()\n",
    "\n",
    "# random seed is not common with model training on the other notebook\n",
    "test_idx = np.random.permutation(len(df))\n",
    "#train_up_to = int(len(df) * TRAIN_TEST_SPLIT)\n",
    "#test_idx = p[train_up_to:]\n",
    "\n",
    "df['gender_id'] = df['gender'].map(lambda gender: GENDER_ID_MAP[gender])\n",
    "df['race_id'] = df['race'].map(lambda race: RACE_ID_MAP[race])\n",
    "\n",
    "max_age = df['age'].max()\n",
    "\n",
    "#test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean model\n",
    "model_path = \"./models/weighted_forked_VGG_model.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'age_output_loss': 0.013008764944970608,\n",
       " u'age_output_mae': 0.08374863862991333,\n",
       " u'gender_output_accuracy': 0.9778645634651184,\n",
       " u'gender_output_loss': 0.09247779101133347,\n",
       " 'loss': 1.0672260522842407,\n",
       " u'race_output_accuracy': 0.8815104365348816,\n",
       " u'race_output_loss': 0.6765839457511902}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eps = 0\n",
    "test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n",
      "yielded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{u'age_output_loss': 0.2050456702709198,\n",
       " u'age_output_mae': 0.44825080037117004,\n",
       " u'gender_output_accuracy': 0.729567289352417,\n",
       " u'gender_output_loss': 0.4536042809486389,\n",
       " 'loss': 1407.423828125,\n",
       " u'race_output_accuracy': 0.0,\n",
       " u'race_output_loss': 1481.29296875}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.2\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=32)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 2\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 3\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 4\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 5\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[(df.gender == 'female') & (df.race == 'black')].file)# and race == black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
