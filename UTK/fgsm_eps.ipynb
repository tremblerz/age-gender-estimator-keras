{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from preprocessor import _imread as imread\n",
    "from preprocessor import _imresize as imresize\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.losses import categorical_crossentropy\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'male', 1: 'female'},\n",
       " {'female': 1, 'male': 0},\n",
       " {0: 'white', 1: 'black', 2: 'asian', 3: 'indian', 4: 'others'},\n",
       " {'asian': 2, 'black': 1, 'indian': 3, 'others': 4, 'white': 0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"data/UTKFace\"\n",
    "TRAIN_TEST_SPLIT = 0.7\n",
    "IM_WIDTH = IM_HEIGHT = 198\n",
    "input_shape = (IM_WIDTH, IM_HEIGHT, 3)\n",
    "ID_GENDER_MAP = {0: 'male', 1: 'female'}\n",
    "GENDER_ID_MAP = dict((g, i) for i, g in ID_GENDER_MAP.items())\n",
    "ID_RACE_MAP = {0: 'white', 1: 'black', 2: 'asian', 3: 'indian', 4: 'others'}\n",
    "RACE_ID_MAP = dict((r, i) for i, r in ID_RACE_MAP.items())\n",
    "\n",
    "ID_GENDER_MAP, GENDER_ID_MAP, ID_RACE_MAP, RACE_ID_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filepath(filepath):\n",
    "    try:\n",
    "        path, filename = os.path.split(filepath)\n",
    "        filename, ext = os.path.splitext(filename)\n",
    "        age, gender, race, _ = filename.split(\"_\")\n",
    "        return int(age), ID_GENDER_MAP[int(gender)], ID_RACE_MAP[int(race)]\n",
    "    except Exception as e:\n",
    "        print(filepath)\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/UTKFace/61_1_20170109142408075.jpg.chip.jpg\n",
      "data/UTKFace/39_1_20170116174525125.jpg.chip.jpg\n",
      "data/UTKFace/61_1_20170109150557335.jpg.chip.jpg\n"
     ]
    }
   ],
   "source": [
    "# create a pandas data frame of images, age, gender and race\n",
    "files = glob.glob(os.path.join(DATA_DIR, \"*.jpg\"))\n",
    "attributes = list(map(parse_filepath, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>data/UTKFace/28_1_0_20170116164219746.jpg.chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>data/UTKFace/24_1_0_20170117150731090.jpg.chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "      <td>data/UTKFace/24_1_1_20170113003752421.jpg.chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>indian</td>\n",
       "      <td>data/UTKFace/26_1_3_20170104235148954.jpg.chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51.0</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>data/UTKFace/51_0_0_20170117190825002.jpg.chip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender    race                                               file\n",
       "0  28.0  female   white  data/UTKFace/28_1_0_20170116164219746.jpg.chip...\n",
       "1  24.0  female   white  data/UTKFace/24_1_0_20170117150731090.jpg.chip...\n",
       "3  24.0  female   black  data/UTKFace/24_1_1_20170113003752421.jpg.chip...\n",
       "4  26.0  female  indian  data/UTKFace/26_1_3_20170104235148954.jpg.chip...\n",
       "5  51.0    male   white  data/UTKFace/51_0_0_20170117190825002.jpg.chip..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(attributes)\n",
    "df['file'] = files\n",
    "df.columns = ['age', 'gender', 'race', 'file']\n",
    "df = df.dropna()\n",
    "df = df[(df['age'] > 10) & (df['age'] < 65)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, input_shape):\n",
    "    image = imresize(image, input_shape[:2])\n",
    "    image = image.astype('float32')\n",
    "    image = image/255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "def predict(model, image):\n",
    "    predictions = model.predict(image)\n",
    "    return predictions\n",
    "\n",
    "def FGSM(x, model, race_label, gender_label, alpha_1, alpha_2):\n",
    "    sess = K.get_session()\n",
    "    x_adv1 = x\n",
    "    x_adv2 = x\n",
    "    x_adv3 = x\n",
    "    x_adv4 = x\n",
    "    x_adv5 = x\n",
    "    #alpha_1 = 1.\n",
    "    #alpha_2 = -1.\n",
    "    #print(list(map(lambda x: x.name, model.layers)))\n",
    "    # dense7 -> layer before race output\n",
    "    # dense8 -> layer before gender output\n",
    "    # dense_7 = model.get_layer('dense_7').output\n",
    "    # dense_7_grads = K.gradients(dense_7, model.input)\n",
    "\n",
    "    # dense_8 = model.get_layer('dense_8').output\n",
    "    # dense_8_grads = K.gradients(dense_8, model.input)\n",
    "\n",
    "    # final_grads = tf.constant(alpha_1) * dense_7_grads + tf.constant(alpha_2) * dense_8_grads\n",
    "    # grads = K.gradients(final_grads, model.input)\n",
    "    \n",
    "    # delta = K.sign(final_grads[0])\n",
    "    \n",
    "    race_output = model.get_layer('race_output').output\n",
    "    print(\"race_output {}\".format(race_output))\n",
    "    gender_output = model.get_layer('gender_output').output\n",
    "    print(\"gender_output {}\".format(gender_output))\n",
    "\n",
    "    race_loss = K.sum(categorical_crossentropy(race_label, race_output))\n",
    "    gender_loss = K.sum(categorical_crossentropy(gender_label, gender_output))\n",
    "    \n",
    "    #race_loss_val, gender_loss_val = sess.run([race_loss, gender_loss], feed_dict={model.input: x})\n",
    "    #print(race_loss_val, gender_loss_val)\n",
    "\n",
    "    loss = alpha_1 * race_loss + alpha_2 * gender_loss\n",
    "    grads = K.gradients(loss, model.input)\n",
    "    delta = K.sign(grads[0])\n",
    "\n",
    "    x_adv1 = x_adv1 + 0.1 * delta\n",
    "    x_adv2 = x_adv2 + 0.2 * delta\n",
    "    x_adv3 = x_adv3 + 0.3 * delta\n",
    "    x_adv4 = x_adv4 + 0.4 * delta\n",
    "    x_adv5 = x_adv5 + 0.5 * delta\n",
    "\n",
    "    x_adv1 = K.clip(x_adv1, 0.0 ,1.0)\n",
    "    x_adv2 = K.clip(x_adv2, 0.0 ,1.0)\n",
    "    x_adv3 = K.clip(x_adv3, 0.0 ,1.0)\n",
    "    x_adv4 = K.clip(x_adv4, 0.0 ,1.0)\n",
    "    x_adv5 = K.clip(x_adv5, 0.0 ,1.0)\n",
    "\n",
    "    gradients, x_adv1_array, x_adv2_array, x_adv3_array, x_adv4_array, x_adv5_array = sess.run([grads,\n",
    "                                                                                                x_adv1,\n",
    "                                                                                                x_adv2,\n",
    "                                                                                                x_adv3,\n",
    "                                                                                                x_adv4,\n",
    "                                                                                                x_adv5],\n",
    "                                                                                                feed_dict={model.input:x})\n",
    "    #print('GRADIENT SUM:{}'.format(np.sum(gradients[0])))\n",
    "    return x_adv1_array, x_adv2_array, x_adv3_array, x_adv4_array, x_adv5_array\n",
    "\n",
    "def plot_adversarial(img_list):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    eps = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    for n, img in enumerate(img_list):\n",
    "        ax = plt.subplot(2,3,n+1)\n",
    "        ax.set_title('Epsilon: {}'.format(eps[n]))\n",
    "        plt.imshow(img[0])\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(x, race_label, gender_label, alpha_1, alpha_2, eps, steps):\n",
    "    x_adv = model.input\n",
    "    race_output = model.get_layer('race_output').output\n",
    "    gender_output = model.get_layer('gender_output').output\n",
    "\n",
    "    race_loss = K.sum(categorical_crossentropy(race_label, race_output))\n",
    "    gender_loss = K.sum(categorical_crossentropy(gender_label, gender_output))\n",
    "\n",
    "    loss = alpha_1 * race_loss + alpha_2 * gender_loss\n",
    "    grads = K.gradients(loss, model.input)\n",
    "    delta = K.sign(grads[0])\n",
    "\n",
    "    x_adv = x_adv + eps * delta\n",
    "    x_adv = K.clip(x_adv, 0.0, 1.0)\n",
    "\n",
    "    for step in range(steps):\n",
    "        # predictions = predict(model, x)\n",
    "        # print(predictions)\n",
    "        # print(x.shape)\n",
    "        x_adv_array = sess.run([x_adv], feed_dict={model.input: x})\n",
    "        # print(x_adv_array[0].shape)\n",
    "        x = x_adv_array[0]\n",
    "        #break\n",
    "    return x_adv_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_model_path = \"./models/VGG16_adv_model.h5\"\n",
    "clean_model_path = \"./models/weighted_forked_VGG_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv_samples(x, model):\n",
    "    adv_sample = FGSM(x, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_adv_samples(generator, eps):\n",
    "    folder = \"adv_generated_imgs_pgd\"\n",
    "    for data in generator:\n",
    "        samples, labels, filenames = data\n",
    "        race_one_hot, gender_one_hot = labels[1], labels[2]\n",
    "        # running loop over a batch\n",
    "        # prediction = predict(model, samples)\n",
    "\n",
    "        adv_samples = PGD(samples, race_label=race_one_hot, gender_label=gender_one_hot,\n",
    "                          alpha_1=0.1, alpha_2=-1., eps=eps, steps=20)\n",
    "        for index in range(len(adv_samples)):\n",
    "            filename = filenames[index]\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, eps, filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[index]*255))\n",
    "            img.save(final_name)\n",
    "            \n",
    "            \"\"\"final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"1\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[0][index]*255))\n",
    "            img.save(final_name)\n",
    "\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"2\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[1][index]*255))\n",
    "            img.save(final_name)\n",
    "\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"3\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[2][index]*255))\n",
    "            img.save(final_name)\n",
    "\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"4\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[3][index]*255))\n",
    "            img.save(final_name)\n",
    "\n",
    "            final_name = \"{}/{}/{}/{}\".format(filename.split(\"/\")[0], folder, \"5\", filename.split(\"/\")[-1])\n",
    "            img = Image.fromarray(np.uint8(adv_samples[4][index]*255))\n",
    "            img.save(final_name)\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "def get_data_generator(df, indices, for_training, batch_size=16):\n",
    "    # filenames variable is not being passed right now for the evaluation but would be\n",
    "    # required if we want to generate the dataset of adversarial images\n",
    "    images, ages, races, genders, filenames = [], [], [], [], []\n",
    "    while True:\n",
    "        for i in indices:\n",
    "            r = df.iloc[i]\n",
    "            file, age, race, gender = r['file'], r['age'], r['race_id'], r['gender_id']\n",
    "            im = Image.open(file)\n",
    "            im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "            im = np.array(im) / 255.0\n",
    "            filenames.append(file)\n",
    "            images.append(im)\n",
    "            ages.append(age / max_age)\n",
    "            races.append(to_categorical(race, len(RACE_ID_MAP)))\n",
    "            genders.append(to_categorical(gender, 2))\n",
    "            if len(images) >= batch_size:\n",
    "                yield np.array(images), [np.array(ages), np.array(races), np.array(genders)], filenames\n",
    "                images, ages, races, genders, filenames = [], [], [], [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed is not common with model training on the other notebook\n",
    "p = np.random.permutation(len(df))\n",
    "train_up_to = int(len(df) * TRAIN_TEST_SPLIT)\n",
    "test_idx = p[train_up_to:]\n",
    "\n",
    "df['gender_id'] = df['gender'].map(lambda gender: GENDER_ID_MAP[gender])\n",
    "df['race_id'] = df['race'].map(lambda race: RACE_ID_MAP[race])\n",
    "\n",
    "max_age = df['age'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(clean_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image(sample_num=None):\n",
    "    if sample_num is None:\n",
    "        random_record = df.sample().iloc[0]\n",
    "    else:\n",
    "        random_record = df.iloc[sample_num]\n",
    "    \n",
    "    img_path = random_record['file']\n",
    "    image = imread(img_path)\n",
    "    image = preprocess_image(image, input_shape)\n",
    "\n",
    "    race_label = random_record['race_id']\n",
    "    gender_label = random_record['gender_id']\n",
    "\n",
    "    race_one_hot = np_utils.to_categorical(race_label, len(ID_RACE_MAP))\n",
    "    gender_one_hot = np_utils.to_categorical(gender_label, len(ID_GENDER_MAP))\n",
    "\n",
    "    return image, gender_one_hot, race_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbed_random_image(eps, index, sample_num=None):\n",
    "    #index = np.random.choice(indices)\n",
    "    #if sample_num is None:\n",
    "    #    random_record = df.sample().iloc[0]\n",
    "    #else:\n",
    "    random_record = df.iloc[index]\n",
    "\n",
    "    file = random_record['file']\n",
    "    folder = \"adv_generated_imgs_pgd\"\n",
    "    filename = \"./{}/{}/{}/{}\".format(file.split(\"/\")[0], folder, str(eps), file.split(\"/\")[-1])\n",
    "\n",
    "    image = imread(filename)\n",
    "    image = preprocess_image(image, input_shape)\n",
    "\n",
    "    race_label = random_record['race_id']\n",
    "    gender_label = random_record['gender_id']\n",
    "\n",
    "    race_one_hot = np_utils.to_categorical(race_label, len(ID_RACE_MAP))\n",
    "    gender_one_hot = np_utils.to_categorical(gender_label, len(ID_GENDER_MAP))\n",
    "\n",
    "    return image, gender_one_hot, race_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gender_one_hot, race_one_hot = random_image(114)\n",
    "\n",
    "predictions = predict(model, image)\n",
    "\n",
    "images = FGSM(image, model, race_one_hot, gender_one_hot, alpha_1 = 1., alpha_2 = 0.)\n",
    "\n",
    "plot_adversarial(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-fd590de5588b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# images = FGSM(image, model, race_one_hot, gender_one_hot, alpha_1 = 10., alpha_2 = -10.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# image = PGD(image, race_one_hot, gender_one_hot, alpha_1 = 1., alpha_2 = -1., eps=0.1, steps=20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print(out[1], out[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#print(predi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "race = [0,0,0,0]\n",
    "gender = [0,0]\n",
    "for idx in test_idx:\n",
    "    image, gender_one_hot, race_one_hot = perturbed_random_image(0.2, idx)\n",
    "\n",
    "    #predictions = predict(model, image)\n",
    "    \n",
    "    # images = FGSM(image, model, race_one_hot, gender_one_hot, alpha_1 = 10., alpha_2 = -10.)\n",
    "    # image = PGD(image, race_one_hot, gender_one_hot, alpha_1 = 1., alpha_2 = -1., eps=0.1, steps=20)\n",
    "    out = model.predict(image)\n",
    "    #print(out[1], out[2])\n",
    "    #print(predi)\n",
    "    #plot_adversarial(image)\n",
    "    race[np.argmax(out[1])] += 1\n",
    "    gender[np.argmax(out[2])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdfde776150>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdfde660710>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2283, 42, 0, 428]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8292771521976026"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(race[0]) / sum(race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5559"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = [0, 0, 0, 0, 0]\n",
    "gender = [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1078, 640, 323, 530, 182]\n"
     ]
    }
   ],
   "source": [
    "for idx in test_idx[:2753]:\n",
    "    rec = df.iloc[idx]\n",
    "    #print(rec['race_id'])\n",
    "    gender[rec['gender_id']] += 1\n",
    "    race[rec['race_id']] += 1\n",
    "print(race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3915728296403923"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(race[0]) / sum(race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1455, 1298]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5285143479840174"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(gender[0]) / sum(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_adv_samples(test_gen, eps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate clean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv_data_generator(df, indices, eps, for_training=False, batch_size=128):\n",
    "    images, ages, races, genders = [], [], [], []\n",
    "    folder = \"adv_generated_imgs_pgd\"\n",
    "    while True:\n",
    "        for i in indices:\n",
    "            r = df.iloc[i]\n",
    "            file, age, race, gender = r['file'], r['age'], r['race_id'], r['gender_id']\n",
    "            filename = \"{}/{}/{}/{}\".format(file.split(\"/\")[0], folder, str(eps), file.split(\"/\")[-1])\n",
    "            #if os.path.exists(filename):\n",
    "            im = Image.open(filename)\n",
    "            im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "            im = np.array(im) / 255.0\n",
    "            images.append(im)\n",
    "            ages.append(age / max_age)\n",
    "            races.append(to_categorical(race, len(RACE_ID_MAP)))\n",
    "            genders.append(to_categorical(gender, 2))\n",
    "            if len(images) >= batch_size:\n",
    "                #print(\"yielded\")\n",
    "                yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]\n",
    "                images, ages, races, genders = [], [], [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas data frame of images, age, gender and race\n",
    "ADV_DATA_DIR = \"./data/adv_generated_imgs_pgd/0.2/\"\n",
    "files = glob.glob(os.path.join(ADV_DATA_DIR, \"*.jpg\"))\n",
    "attributes = list(map(parse_filepath, files))\n",
    "\n",
    "df = pd.DataFrame(attributes)\n",
    "df['file'] = files\n",
    "df.columns = ['age', 'gender', 'race', 'file']\n",
    "df = df.dropna()\n",
    "df = df[(df['age'] > 10) & (df['age'] < 65)]\n",
    "#df.head()\n",
    "\n",
    "# random seed is not common with model training on the other notebook\n",
    "test_idx = np.random.permutation(len(df))\n",
    "#train_up_to = int(len(df) * TRAIN_TEST_SPLIT)\n",
    "#test_idx = p[train_up_to:]\n",
    "\n",
    "df['gender_id'] = df['gender'].map(lambda gender: GENDER_ID_MAP[gender])\n",
    "df['race_id'] = df['race'].map(lambda race: RACE_ID_MAP[race])\n",
    "\n",
    "max_age = df['age'].max()\n",
    "\n",
    "#test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean model\n",
    "model_path = \"./models/weighted_forked_VGG_model.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'age_output_loss': 0.011946349404752254,\n",
       " u'age_output_mae': 0.0805635079741478,\n",
       " u'gender_output_accuracy': 0.976017415523529,\n",
       " u'gender_output_loss': 0.12335702776908875,\n",
       " 'loss': 0.6523380279541016,\n",
       " u'race_output_accuracy': 0.8800871968269348,\n",
       " u'race_output_loss': 0.5985112190246582}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eps = 0\n",
    "# test_gen = get_data_generator(df, test_idx, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'age_output_loss': 0.0446450412273407,\n",
       " u'age_output_mae': 0.15803809463977814,\n",
       " u'gender_output_accuracy': 0.9980014562606812,\n",
       " u'gender_output_loss': 0.03714361414313316,\n",
       " 'loss': 1463.7095947265625,\n",
       " u'race_output_accuracy': 0.0,\n",
       " u'race_output_loss': 1486.427734375}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.2\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean model\n",
    "model_path = \"./models/resnet50_model.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'age_output_loss': 0.10832329839468002,\n",
       " u'age_output_mae': 0.2706315815448761,\n",
       " u'gender_output_accuracy': 0.5268895626068115,\n",
       " u'gender_output_loss': 7.587944030761719,\n",
       " 'loss': 19.445199966430664,\n",
       " u'race_output_accuracy': 0.39662063121795654,\n",
       " u'race_output_loss': 13.472764015197754}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eps = 0.2\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean model\n",
    "model_path = \"./models/mobilenet_model.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'age_output_loss': 0.04689286649227142,\n",
       " u'age_output_mae': 0.1844833493232727,\n",
       " u'gender_output_accuracy': 0.4505814015865326,\n",
       " u'gender_output_loss': 1.069699764251709,\n",
       " 'loss': 6.1234564781188965,\n",
       " u'race_output_accuracy': 0.39643895626068115,\n",
       " u'race_output_loss': 4.847633361816406}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of MobileNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean model\n",
    "model_path = \"./models/mobilenet_model.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'age_output_loss': 0.04766557365655899,\n",
       " u'age_output_mae': 0.18656139075756073,\n",
       " u'gender_output_accuracy': 0.4596656858921051,\n",
       " u'gender_output_loss': 1.053579568862915,\n",
       " 'loss': 6.033567428588867,\n",
       " u'race_output_accuracy': 0.39662063121795654,\n",
       " u'race_output_loss': 4.8335862159729}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of VGG19 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean model\n",
    "model_path = \"./models/vgg19_model.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'age_output_loss': 0.06575646996498108,\n",
       " u'age_output_mae': 0.207205668091774,\n",
       " u'gender_output_accuracy': 0.5401526093482971,\n",
       " u'gender_output_loss': 1.6036206483840942,\n",
       " 'loss': 5.338807582855225,\n",
       " u'race_output_accuracy': 0.3088662922382355,\n",
       " u'race_output_loss': 3.3931243419647217}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 2\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 3\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 4\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 5\n",
    "test_gen = get_adv_data_generator(df, test_idx, eps, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_idx)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[(df.gender == 'female') & (df.race == 'black')].file)# and race == black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
